{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3aeef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "import requests\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c491066",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca470ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "serper = GoogleSerperAPIWrapper()\n",
    "tool_search = Tool(\n",
    "    name=\"search\",\n",
    "    func=serper.run,\n",
    "    description=\"Useful for when you need more information from an online search\"\n",
    ")\n",
    "\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "\n",
    "def pushover_notification(message):\n",
    "    url = \"https://api.pushover.net/1/messages.json\"\n",
    "    data = {\n",
    "        \"token\": pushover_token,\n",
    "        \"user\": pushover_user,\n",
    "        \"message\": message,\n",
    "    }\n",
    "    requests.post(url, data=data)\n",
    "\n",
    "tool_push = Tool(\n",
    "    name=\"send_push_notification\",\n",
    "    func=pushover_notification,\n",
    "    description=\"Useful for sending push notifications to your phone\"\n",
    ")\n",
    "tools = [tool_search, tool_push]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd14ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Initialise the State\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step2: Start the Graph Builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Step3: Create Nodes\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "def chat_node(old_state: State):\n",
    "    response = llm_with_tools.invoke(old_state.messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(\"chat_node\", chat_node)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Step4: Creat Edges\n",
    "graph_builder.add_conditional_edges('chat_node', tools_condition, 'tools')\n",
    "graph_builder.add_edge('tools', 'chat_node')\n",
    "graph_builder.add_edge(START, 'chat_node')\n",
    "\n",
    "# Step5: Create the Graph\n",
    "# Now if we want to add memory to the graph we can do this by adding a checkpoint to the graph\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH Invoke\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "def chat(user_input: str, history):\n",
    "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the current state of the graph\n",
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of states\n",
    "list(graph.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01f95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "db_path = \"checkpoints.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "sql_memory = SqliteSaver(conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6417e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Initialise the State\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Step2: Start the Graph Builder\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Step3: Create Nodes\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "def chat_node(old_state: State):\n",
    "    response = llm_with_tools.invoke(old_state.messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "graph_builder.add_node(\"chat_node\", chat_node)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Step4: Creat Edges\n",
    "graph_builder.add_conditional_edges('chat_node', tools_condition, 'tools')\n",
    "graph_builder.add_edge('tools', 'chat_node')\n",
    "graph_builder.add_edge(START, 'chat_node')\n",
    "\n",
    "# Step5: Create the Graph\n",
    "# Now if we want to add memory to the graph we can do this by adding a checkpoint to the graph\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=sql_memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "def chat(user_input: str, history):\n",
    "    result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config=config)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c68938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
